\chapter{Entropy}
\begin{mdframed}[linewidth=2,leftmargin=108,rightmargin=108,skipbelow=30]
	\textbf{Throughout this chapter $(X, \B, \mu)$ will denote a probability space.}
\end{mdframed}

\section{Isomorphisms of measure-preserving transformations}
One of the main problems in ergodic theory is to classify measure-preserving transformations. To this end, we want to decide the conditions required for two measure-preserving transformations to be `the same' -- up to sets of measure zero.

\subsection{Isomorphism and conjugacy of measure spaces}
\emph{This subsection predominantly follows \cite[Chapter 2]{walters:intro-to-ergodic-theory}.}

We begin by defining when two probability spaces are isomorphic or conjugate.

\begin{definition}
	Two probability spaces $(X_1, \B_1, \mu_1), (X_2, \B_2, \mu_2)$ are \key{isomorphic} if there exists $M_1 \in \B_1$, $M_2 \in \B_2$ such that $\mu_1(M_1) = 1 = \mu_2(M_2)$ and if there exists an invertible measure-preserving transformation $\phi: M_1 \to M_2$.
\end{definition}

Let $A, C \subset \B$. We define an equivalence relation on $\B$: we have $A \sim C$ if and only if $\mu(A \symdiff C) = 0$. In other words, $A$ and $C$ belong to the same equivalence class if they are equal almost everywhere. It can be easily checked that $\sim$ is indeed an equivalence relation.

Let $\tilde{\B}$ denote the collection of all equivalence classes in $\B$. Since $\B$ is a $\sigma$-algebra, it is clear that $\tilde{B}$ is also a $\sigma$-algebra. We can define a measure $\tilde{\mu} : \tilde{\B} \to \reals^+$ by $\tilde{\mu}(\tilde{B}) = \mu(B)$, where $B$ belongs to the equivalence class $\tilde{B}$.

\begin{definition}
	A \key{measure algebra} is a Boolean $\sigma$-algebra equipped with a measure.
\end{definition}

In view of this definition, we see that $(\tilde{\B}, \tilde{\mu})$ is a \key{measure algebra}.

\begin{definition}
	Let $(X_1, \B_1, \mu_1), (X_2, \B_2, \mu_2)$ be probability spaces with corresponding measure algebras $(\tilde{\B}_1, \tilde{\mu}_1), (\tilde{\B}_2, \tilde{\mu}_2)$, respectively.
	
	We say $(\tilde{\B}_1, \tilde{\mu}_1)$ and $(\tilde{\B}_2, \tilde{\mu}_2)$ are \key{isomorphic} if there exists a bijection $\phi : \tilde{\B}_2 \to \tilde{\B}_1$ which preserves complmentation and countable unions and intersections such that $\tilde{\mu}_1(\phi \tilde{B}) = \tilde{\mu}_2(\tilde{B})$ for all $\tilde{B} \in \tilde{\B}_2$.
	
	The probability spaces $(X_1, \B_1, \mu_1)$ and $(X_2, \B_2, \mu_2)$ are \key{conjugate} if their corresponding measure algebras are isomorphic.
\end{definition}

\begin{proposition}
	If two probability spaces are isomorphic then they are also conjugate.
	\begin{proof}
		Suppose $(X_1, \B_1, \mu_1), (X_2, \B_2, \mu_2)$ are isomorphic probability spaces with corresponding measure algebras $(\tilde{\B}_1, \tilde{\mu}_1), (\tilde{\B}_2, \tilde{\mu}_2)$. By definition, this means there exists $M_1 \in \B_1$, $M_2 \in \B_2$ such that $\mu_1(M_1) = 1 = \mu_2(M_2)$ and there exists an invertible measure-preserving transformation $\phi: M_1 \to M_2$.
		
		Now we can define the map
		\[
			\psi : \tilde{\B}_2 \to \tilde{\B}_1 : \tilde{B} \mapsto (\phi^{-1}(M_2 \cap B))^\sim.
		\]
		This is clearly a bijection and, since $\phi$ is measure-preserving and $M_2 = X_2$ almost everywhere, we have
		\[
			\tilde{\mu}_1(\psi\tilde{B}) = \tilde{\mu}_1(\phi^{-1}(M_2 \cap B))^\sim = \tilde{\mu}_2(M_2 \cap B)^\sim = \tilde{\mu}_2(\tilde{B}),
		\]
		for all $\tilde{B} \in \tilde{\B}_2$. Therefore the measure algebras are isomorphic and hence the corresponding measure spaces are isomorphic.
	\end{proof}
\end{proposition}

The converse statement is not necessarily true. Indeed, suppose we have the probability space $(X_1, \B_1, \mu_1)$ consisting of exactly one point, and another probability space $(X_2, \B_2, \mu_2)$ consisting of exactly two points, with $\B_2 = \{\emptyset, X_2\}$. It is easy to see that the measure algebras are isomorphic and hence the measure spaces are conjugate.

We need to choose $M_1 \in \B_1$, $M_2 \in \B_2$ such that $\mu_1(M_1) = 1 = \mu_2(M_2)$; the only possibility is $M_1 = X_1$ and $M_2 = X_2$. However there does not exist bijection between these two sets, so the probability spaces are \emph{isomorphic}.

\subsection{A motivational example}
We describe a scenario when two measure-preserving transformations could be considered `the same'. We follow the example in \cite[p58]{walters:intro-to-ergodic-theory}.

We first introduce a new probability space.

\begin{comment}
Let $Y = \{0, 1\}$ and let $(p_0, p_1)$ be a probability vector with no zero entries. Then $(Y, 2^Y, \nu)$ is a measure space, with measure $\nu$ defined by $\nu(y) = p_y$ for $y \in Y$. Now let $X = \{(x_j)_{j = 0}^\infty \mid x_j \in Y\}$, the space of infinite sequences with entries in $Y = \{0, 1\}$.
\end{comment}
\subsubsection{Bernoulli shifts}
Let $Y = \{0, 1, \dots, k\}$ be a set of $k$ symbols and let $p = (p_0, p_1, \dots, p_k)$ be a probability vector with no zero entries. Let $X = \{(x_j)_{j = 0}^\infty \mid x_j \in Y \text{ for all } j \geq 0\}$ be the space of infinite sequences with entries in $Y$. We may define a measure $\nu$ on cylinders of length $n$ by
\[
	\nu[x_0, x_1, \dots, x_{n - 1}] = p_{x_0} p_{x_1} \dots p_{x_{n - 1}}.
\]
Such measures are known as \key{Bernoulli measures}. Let $\sigma : X \to X$ be the one-sided, left shift map on $X$.

\begin{proposition}
	The measure $\nu$ is $\sigma$-invariant.
	\begin{proof}
		We have
		\begin{align*}
			\nu(\sigma^{-1}[x_1, \dots, x_n]) &= \nu\left(\bigsqcup_{j = 0}^{k - 1}{[j, x_1, \dots, x_n]}\right) \\
				&= \sum_{j = 0}^{k - 1}{\nu[j, x_1, \dots, x_n]} \\
				&= \sum_{j = 0}^{k - 1}{p_j p_{x_1} \dots p_{x_n}} \\
				&= p_{x_1} \dots p_{x_n} \\
				&= \nu[x_1, \dots, x_n].
		\end{align*}
		(We have used the fact that $\sum_{j = 0}^{k - 1}{p_j} = 1$ on the penultimate line.)
	\end{proof}
\end{proposition}

The shift map $\sigma$ is called the one-sided $(p_0, p_1, \dots, p_{k - 1})$-shift.

We are now ready to present two measure-preserving transformations which we argue are `the same'.

\subsubsection{The \texorpdfstring{($\mathbf{\frac{1}{2}, \frac{1}{2}}$)}{(1/2, 1/2)}-shift and the doubling map}
Let $T : ([0, 1), \B, \mu) \to ([0, 1), \B, \mu) : x \mapsto 2x \bmod 1$ be the doubling map, where $\B$ is the Borel $\sigma$-algebra on $[0, 1)$ and $\mu$ is Lebesgue measure.

Let $\sigma : (X, \C, \nu) \to (X, \C, \nu)$ be the $(\frac{1}{2}, \frac{1}{2})$-shift, where $X = \{(x_j)_{j = 0}^\infty \mid x_j \in \{0, 1\} \text{ for all } j \geq 0\}$, $\C$ is the $\sigma$-algebra generated by all cylinders in $X$, and $\nu$ is the Bernoulli measure as described above.

Define the map $\phi : X \to [0, 1)$ by
\[
	\phi(x_0, x_1, \dots) = \sum_{j = 0}^\infty{\frac{x_j}{2^{j + 1}}} = \frac{x_0}{2^1} + \frac{x_1}{2^2} + \frac{x_2}{2^3} + \dots.
\]
It is easy to see that $\phi$ maps the binary expansion of a number to the actual number itself.

Let $E = \{(x_j)_{j = 0}^\infty \in X \mid (x_j)_{j = N}^\infty \text{ is constant for some } N \geq 0\}$ be the set of sequences in $X$ whose coordinates are eventually constant. Now, if the binary expansion of a number is \emph{not} eventually constant, then this binary expansion is unique. Therefore $\phi$ is \emph{injective} on $X \setminus E$. It is also clear that $\phi$ is \emph{surjective}, since every number in $[0, 1)$ has at least one binary expansion. It is also easy to see that $\phi \circ \sigma = T \circ \phi$.

We now show that $\phi$ is measure-preserving. Let $[\frac{a}{2^s}, \frac{a + 1}{2^s}] \subset [0, 1)$ be a dyadic interval, where $s \in \naturals$. We can write
\[
	\frac{a}{2^s} = \sum_{j = 0}^{s - 1}{\frac{a_j}{2^j}} \quad \text{and} \quad \frac{a + 1}{2^s} = \sum_{j = 0}^\infty{\frac{a_j}{2^j}},
\]
where $a_j \in \{0, 1\}$ for $j = 0, 1, \dots, s - 2$ and $a_k = 1$ for $k \geq s - 1$. In other words, the binary expansion of all numbers in the interval $[\frac{a}{2^s}, \frac{a + 1}{2^s}]$ agree in the first $s$ positions. Thus, \begin{align*}
	\nu\left(\phi^{-1}\left[\frac{a}{2^s}, \frac{a + 1}{2^s}\right]\right) &= \nu[a_0, a_1, \dots, a_{s - 1}] \\
		&= \frac{1}{2^s} \\
		&= \mu\left[\frac{a}{2^s}, \frac{a + 1}{2^s}\right].
\end{align*}
Hence $\phi$ is measure-preserving on dyadic intervals, which generate the Borel $\sigma$-algebra $\B$ on $[0, 1)$. We may therefore apply the Kolmogorov Extension Theorem and it follows that $\phi$ is \emph{measure-preserving} on all Borel sets $B \in \B$.

Let $D = \{\frac{a}{2^s} \in [0, 1) \mid s \in \naturals,\ 0 \leq a < s^s\}$ be the set of all dyadic rationals in $[0, 1)$. Clearly, $T^{-1}D = D$ and this means that $T^{-1}([0, 1) \setminus D) = [0, 1) \setminus D$. Since $D \subset \rationals$, we have $\mu(D) = 0$.

It is also clear that $\sigma^{-1}E = E$ and so $\sigma^{-1}(X \setminus E) = X \setminus E$. Since there are countably many sequences in $E$, we have $\nu(E) = 0$.

By the above observations...

\section{Conditional expectation}
\begin{definition}
	Conditional expectation operator $E(\:\cdot \mid \C) : L^1(X, \B, \mu) \to L^1(X, \C, \mu)$ is defined...
\end{definition}

The operator $E(f \mid \C)$ is uniquely determined by the requirement that:
\begin{enumerate}
	\item $E(f \mid \C)$ is $\C$-measurable, and
	\item for all $C \in \C$ we have
	\[
	\int_C{f\ d\mu} = \int_C{E(f \mid \C)\ d\mu}.
	\]
\end{enumerate}

We can think of $E(f \mid \C)$ as the best approximation of $f$ in the smaller space $\C$ of measurable functions.~\cite[Lecture 21]{ergodic-lectures}

...

\emph{The remainder of this chapter predominantly follows \cite[Chapter 4]{walters:intro-to-ergodic-theory}.}

\section{Conditional entropy}
\begin{theorem}\label{thm:walters-4.3}
	Let $(X, \B, \mu)$ be a probability space and let $\A, \B, \D$ be finite sub-$\sigma$-algebras of $\B$. Suppose $T : X \to X$ is a measure-preserving transformation. Then
	\begin{enumerate}
		\item $H_\mu(\A \join \C \mid \D) = H_\mu(\A \mid \D) + H_\mu(\C \mid \A \join \D)$,
		\item $H_\mu(\A \join \C) = H_\mu(\A) + H_\mu(\C \mid \A)$,
		\item if $\A \subset \C$  then $H_\mu(\A \mid \D) \leq H_\mu(\C \mid \D)$,
		\item if $\A \subset \C$  then $H_\mu(\A) \leq H_\mu(\C)$,
		\item if $\C \subset \D$ then $H_\mu(\A \mid \C) \geq H_\mu(\A \mid \D)$,
		\item $H_\mu(\A) \geq H_\mu(\A \mid \D)$,
		\item $H_\mu(\A \join \C \mid \D) \leq H_\mu(\A \mid \D) + H_\mu(\C \mid \D)$,
		\item $H_\mu(\A \join \C) \leq H_\mu(\A) + H_\mu(\C)$,
		\item $H_\mu(T^{-1}\A \mid T^{-1}\C) = H_\mu(\A \mid \C)$,
		\item $H_\mu(T^{-1}\A) = H_\mu(\A)$.
	\end{enumerate}
	\begin{proof}
		Coming soon!
	\end{proof}
\end{theorem}

...

\begin{theorem}\label{thm:walters-4.12}
	Let $\A, \C$ be finite sub-algebras of $\B$ and let $T$ be a measure-preserving transformation of a probability space $(X, \B, \mu)$ Then
	\begin{enumerate}
		\item $h_\mu(T, \A) \leq H_\mu(\A)$,
		\item $h_\mu(T, \A \join \C) \leq h_\mu(T, \A) + h_\mu(T, \C)$,
		\item if $\A \subset \C$ then $h_\mu(T, \A) \leq h_\mu(T, \C)$,
		\item $h_\mu(T, \A) \leq h_\mu(T, \C) + H_\mu(\A \mid \C)$,
		\item $h_\mu(T, T^{-1}{\A}) = h_\mu(T, \A)$,
		\item if $k \geq 1$ then $h_\mu(T, \A) = h_\mu\left(T, \bigjoin\limits_{i = 0}^{k - 1}{T^{-i}{\A}}\right)$,
		\item if $T$ is invertible and $k \geq 1$ then $h_\mu(T, \A) = h_\mu\left(T, \bigjoin\limits_{i = -k}^k{T^{-i}{\A}}\right)$.
	\end{enumerate}
	\begin{proof}
		Coming soon!
	\end{proof}
\end{theorem}
